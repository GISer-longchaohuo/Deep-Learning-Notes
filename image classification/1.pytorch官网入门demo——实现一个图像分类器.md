# 1.pytorch官网入门demo——实现一个图像分类器

## **demo的流程**

1. model.py ——定义LeNet网络模型

2. train.py ——加载数据集并训练，训练集计算loss，测试集计算accuracy，保存训练好的网络参数

3. predict.py——得到训练好的网络参数后，用自己找的图像进行分类测试

   ![](https://raw.githubusercontent.com/GISer-longchaohuo/Images/master/img/image-20220409211326058.png)

   

   

   [TOC]

   

## 1. model.py

先给出代码，模型是基于LeNet做简单修改，层数很浅

![](https://raw.githubusercontent.com/GISer-longchaohuo/Images/master/img/image-20220204144053172.png)220204144053172.png" alt="image-20220204144053172" style="zoom:80%;" />

```python
# 使用torch.nn包来构建神经网络.
import torch.nn as nn
import torch.nn.functional as F

class LeNet(nn.Module):                #定义一个类（LeNet），继承来自nn.Module这个父类
    # 初始化网络结构
    def __init__(self):                   # 定义初始化函数
        super(LeNet, self).__init__()      # 多继承需用到super函数（super()继承父类的构造函数）
        #定义卷积层
        self.conv1 = nn.Conv2d(3, 16, 5)   #第一个卷积层（深度为3（通道），16个卷积盒，卷积核的尺寸5*5的大小）
        self.pool1 = nn.MaxPool2d(2, 2)     #第一个池化层（尺寸为2*2最大值，步距为2）---下采样层
        self.conv2 = nn.Conv2d(16, 32, 5)   #第二个卷积（深度为16，32个卷积盒，卷积核的尺寸5*5的大小）
        self.pool2 = nn.MaxPool2d(2, 2)     #第二个池化层（尺寸为2*2最大值，步距为2）----下采样层，
        self.fc1 = nn.Linear(32*5*5, 120)   #第一个全连接（全连接是一纬的向量，节点数为120个）
        '''
        在经过第二个池化层后，
        数据还是一个三维的Tensor (32, 5, 5)，
        需要先经过展平(32*5*5)再传到全连接层
        '''
        self.fc2 = nn.Linear(120, 84)      #第二个全连接，节点数为84个
        self.fc3 = nn.Linear(84, 10)        #第三个全连接，节点数为10个，10(就是多少个类别)所处位置的参数需要根据训练集来修改的

    def forward(self, x):         # 正向传播过程，x代表输入的数据（batch[一批图像的个数],channel,height,width）
        #激活函数relu()
        x = F.relu(self.conv1(x))    # input(3, 32, 32) output(16, 28, 28)
        x = self.pool1(x)            # output(16, 14, 14)
        x = F.relu(self.conv2(x))    # output(32, 10, 10)
        x = self.pool2(x)            # output(32, 5, 5)
        #Tensor的展平：view()，在经过第二个池化层后，数据还是一个三维的Tensor (32, 5, 5)，需要先经过展平(32*5*5)再传到全连接层
        x = x.view(-1, 32*5*5)       # output(32*5*5)，-1代表倒数第一个维度
        x = F.relu(self.fc1(x))      # output(120)
        x = F.relu(self.fc2(x))      # output(84)
        x = self.fc3(x)              # output(10)
        return x
```

需注意：

pytorch 中 tensor（也就是输入输出层）的 通道排序为：`[batch, channel, height, width]`
pytorch中的卷积、池化、输入输出层中参数的含义与位置，可配合下图：

![image-20220907110204801](https://raw.githubusercontent.com/GISer-longchaohuo/Images/master/img/image-20220907110204801.png)



### 1.0导入包

```python
# 使用torch.nn包来构建神经网络.
import torch.nn as nn
import torch.nn.functional as F
```



### 1.1 卷积 Conv2d

我们常用的卷积（Conv2d）在pytorch中对应的函数是：

```python
torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')
```

一般使用时关注以下几个参数即可：

| 名词         | 定义                                                         |
| ------------ | ------------------------------------------------------------ |
| in_channels  | 输入特征矩阵的深度。如输入一张RGB彩色图像，那in_channels=3(通道) |
| out_channels | 输出特征矩阵的深度。也等于卷积核的个数，使用n个卷积核输出的特征矩阵深度就是n |
| kernel_size  | 卷积核的尺寸。可以是int类型，如3 代表卷积核的height=width=3，也可以是tuple类型如(3, 5)代表卷积核的height=3，width=5 |
| stride       | 卷积核的步长。默认为1，和kernel_size一样输入可以是int型，也可以是tuple类型 |
| padding      | 补零操作，默认为0。可以为int型如1即补一圈0，如果输入为tuple型如(2, 1) 代表在上下补2行，左右补1列。 |



经卷积后的输出层尺寸计算公式为：
![image-20220907110222584](https://raw.githubusercontent.com/GISer-longchaohuo/Images/master/img/image-20220907110222584.png)

- 输入图片大小 W×W（一般情况下Width=Height）
- Filter大小 F×F
- 步长 S
- padding的像素数 P







### 1.2 池化 MaxPool2d

最大池化（MaxPool2d）在 pytorch 中对应的函数是：

```python
MaxPool2d(kernel_size, stride)
```



### 1.3 Tensor的展平：view()

注意到，在经过第二个池化层后，数据还是一个三维的Tensor (32, 5, 5)，需要先经过展平后(32*5*5)再传到全连接层：

```python
  x = self.pool2(x)            # output(32, 5, 5)
  x = x.view(-1, 32*5*5)       # output(32*5*5)
  x = F.relu(self.fc1(x))      # output(120)


```



### 1.4 全连接 Linear

全连接（ Linear）在 pytorch 中对应的函数是：

```python
Linear(in_features, out_features, bias=True)
```



## 2. train.py

### 2.1 导入数据集

##### 2.1.1导入深度学习所需要的包/库

```python
# 导入包
import torch
import torchvision
import torch.nn as nn
from model import LeNet
import torch.optim as optim
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import time
```

##### 2.1.2数据预处理

- `transforms.ToTensor()` 函数：

​		输入的数据shape[W，H，C ]——>[C，W，H],将所有像素值转为浮点型再除以255，将数据归一化到【0，1】

- `transforms.Normalize（(0.5, 0.5, 0.5), (0.5, 0.5, 0.5)）`函数：

  因为是三通道的原因（三个0.5）

​		标准化（output =(input-0.5)/0.5 ），变换后变成了均值为0 方差为1的正态分布（其实就是最大最小值为1和-1）

```python
# 数据预处理
def main():
    # 对输入的图像数据做预处理，即由shape (H x W x C) in the range [0, 255] → shape (C x H x W) in the range [0.0, 1.0]
    transform = transforms.Compose(
        [transforms.ToTensor(),# (H x W x C) in the range [0, 255]
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])##标准化（output =(input-0.5)/0.5 ）shape (C x H x W) in the range [0.0, 1.0]

```



##### 2.1.3导入、加载 训练集

- 利用`torchvision.datasets`函数可以在线导入pytorch中的数据集
- 利用`torch.utils.data.DataLoader`函数可以加载数据集

```python
#导入、加载 训练集
# 50000张训练图片
# 第一次使用时要将download设置为True才会自动去下载数据集
train_set = torchvision.datasets.CIFAR10(root='./data',# 数据集存放目录
                                         train=True,    # 表示是数据集中的训练集
                                         download=False,
                                         transform=transform)   # 预处理过程
# 加载训练集，实际过程需要分批次（batch）训练
train_loader = torch.utils.data.DataLoader(train_set,    # 导入的训练集
                                           batch_size=36,## 每批训练的样本数
                                           shuffle=True,# 是否打乱训练集
                                           num_workers=0) # 使用线程数，在windows下设置为0
```



##### **2.1.4导入、加载 验证集**

```python
# 10000张验证图片
# 第一次使用时要将download设置为True才会自动去下载数据集
val_set = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=False, # 表示是数据集中的测试集
                                       transform=transform)
# 加载测试集
val_loader = torch.utils.data.DataLoader(val_set,  # 导入的验证集
                                         batch_size=5000,   每批用于验证的样本数
                                         shuffle= False, 
                                         num_workers=0)
# 获取测试集中的图像和标签，用于accuracy计算
test_data_iter = iter(test_loader) #转换成可迭代的迭代器
test_image, test_label = test_data_iter.next()  #next()可获得一批数据
```



### 2.2 训练过程

| 名词              | 定义                                                         |
| ----------------- | ------------------------------------------------------------ |
| epoch             | 对训练集的全部数据进行一次完整的训练，称为 一次 epoch        |
| batch             | 由于硬件算力有限，实际训练时将训练集分成多个批次训练，每批数据的大小为 batch_size |
| iteration 或 step | 对一个batch的数据训练的过程称为 一个 iteration 或 step       |

以本demo为例，训练集一共有50000个样本，batch_size=50，那么完整的训练一次样本：iteration或step=1000，epoch=1

#### 2.2.1  实例化LeNet网络模型（损失函数、优化器）

实例化神经网络模型（LeNet），定义及使用损失函数及优化器

`nn.CrossEntropyLoss()` 函数：结合了nn.LogSoftmax()和nn.NLLLoss()两个函数

`optim.Adam(net.parameters(), lr=0.001)`  函数：net.parameters代表训练参数即LetNet网络模型的可训练全部参数，lr代表学习率

```python
    # 实例化LeNet网络模型
    net = LeNet()   # 定义训练的网络模型
    loss_function = nn.CrossEntropyLoss()   # 定义损失函数为交叉熵损失函数（把sofxmax函数进行内置了）
    optimizer = optim.Adam(net.parameters(), lr=0.001)   ## 定义优化器Adam（net.parameters代表训练参数即LetNet网络模型的可训练参数，lr=学习率）
```



#### 2.2.2  进入模型训练过程

- 设置训练集进行多少次训练
- 遍历训练集，获取训练集的图像和标签
- 清除历史梯度
- 正向传播
- 计算损失
- 反向传播
- 优化器更新参数

```python
    for epoch in range(5):  # loop over the dataset multiple times 一个epoch即对整个训练集进行一次训练

        running_loss = 0.0
        for step, data in enumerate(train_loader, start=0):# 遍历训练集，step从0开始计算（enumerate函数不仅会返回data,还会返回索引）
            # 获取训练集的图像（inputs）和标签（labels）
            inputs, labels = data   # 获取训练集的图像和标签

            # zero the parameter gradients
            optimizer.zero_grad() # 清除历史梯度
            # forward + backward + optimize
            outputs = net(inputs) # 正向传播(将我们输入的图像到神经网络中)
            loss = loss_function(outputs, labels)  # 计算损失（outputs神经网络预测的值，labels-图像真实标签值）
            loss.backward() # 反向传播
            optimizer.step() # 优化器更新参数
```



#### 2.2.3 打印耗时、损失、准确率等数据

```python
  running_loss += loss.item()
            if step % 500 == 499:# print every 500 mini-batches# print every 1000 mini-batches，每500步打印一次
                with torch.no_grad():# 在以下步骤中（验证过程中）不用计算每个节点的损失梯度，防止内存占用。with是上下文管理器
                    outputs = net(val_image)   # 测试集传入网络（test_batch_size=10000），output维度为[10000,10]
                    predict_y = torch.max(outputs, dim=1)[1]# 以output中值最大位置对应的索引（标签）作为预测输出
                    accuracy = torch.eq(predict_y, val_label).sum().item() / val_label.size(0)

                    print('[%d, %5d] train_loss: %.3f  test_accuracy: %.3f' %# 打印epoch，step，loss，accuracy
                          (epoch + 1, step + 1, running_loss / 500, accuracy))
                    running_loss = 0.0

    print('Finished Training')
```



#### 2.2.4保存训练参数

-  `torch.save(net.state_dict(), save_path)`

​		net.state_dict()：以字典的形式

​		save_path：保存参数的路径

```python
    # 保存训练得到的参数
    save_path = './Lenet.pth'
    torch.save(net.state_dict(), save_path)
```



#### 2.2.5train.py 完整代码

```python
    # 实例化LeNet网络模型
    net = LeNet()   # 定义训练的网络模型
    loss_function = nn.CrossEntropyLoss()   # 定义损失函数为交叉熵损失函数（把sofxmax函数进行内置了）
    optimizer = optim.Adam(net.parameters(), lr=0.001)   ## 定义优化器Adam（net.parameters代表训练参数即LetNet网络模型的可训练参数，lr=学习率）
	# 进入训练过程
    for epoch in range(5):  # loop over the dataset multiple times 一个epoch即对整个训练集进行一次训练

        running_loss = 0.0
        for step, data in enumerate(train_loader, start=0):# 遍历训练集，step从0开始计算（enumerate函数不仅会返回data,还会返回索引）
            # 获取训练集的图像（inputs）和标签（labels）
            inputs, labels = data   # 获取训练集的图像和标签

            # zero the parameter gradients
            optimizer.zero_grad() # 清除历史梯度
            # forward + backward + optimize
            outputs = net(inputs) # 正向传播(将我们输入的图像到神经网络中)
            loss = loss_function(outputs, labels)  # # 计算损失（outputs神经网络预测的值，labels-图像真实标签值）
            loss.backward() # 反向传播
            optimizer.step() # 优化器更新参数

            # print statistics
        # 打印耗时、损失、准确率等数据
            running_loss += loss.item()
            if step % 500 == 499:    # print every 500 mini-batches# print every 1000 mini-batches，每500步打印一次
                with torch.no_grad():# 在以下步骤中（验证过程中）不用计算每个节点的损失梯度，防止内存占用。with是上下文管理器
                    outputs = net(val_image)   # 测试集传入网络（test_batch_size=10000），output维度为[10000,10]
                    predict_y = torch.max(outputs, dim=1)[1]# 以output中值最大位置对应的索引（标签）作为预测输出
                    accuracy = torch.eq(predict_y, val_label).sum().item() / val_label.size(0)

                    print('[%d, %5d] train_loss: %.3f  test_accuracy: %.3f' %# 打印epoch，step，loss，accuracy
                          (epoch + 1, step + 1, running_loss / 500, accuracy))
                    running_loss = 0.0

    print('Finished Training')
    # 保存训练得到的参数
    save_path = './Lenet.pth'
    torch.save(net.state_dict(), save_path)


if __name__ == '__main__':
    main()

```

```tex
为什么每计算一个batch(一批训练集数据)，就要调用optimizer.zero_grad()？
            如果不清楚历史梯度，就会对计算的历史梯度进行累加（通过这个特性你能够变现实现一个很大batch数值的训练）
```

打印信息如下：

```python
[1,  1000] train_loss: 1.537  test_accuracy: 0.541
35.345407 s
[2,  1000] train_loss: 1.198  test_accuracy: 0.605
40.532376 s
[3,  1000] train_loss: 1.048  test_accuracy: 0.641
44.144097 s
[4,  1000] train_loss: 0.954  test_accuracy: 0.647
41.313228 s
[5,  1000] train_loss: 0.882  test_accuracy: 0.662
41.860646 s
Finished Training
```



### 2.3 使用GPU/CPU训练

使用下面语句可以在有GPU时使用GPU，无GPU时使用CPU进行训练

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)
```

也可以直接指定

```python
device = torch.device("cuda")
# 或者
# device = torch.device("cpu")
```

对应的，需要用`to()`函数来将Tensor在CPU和GPU之间相互移动，分配到指定的device中计算

```python
net = LeNet()
net.to(device) # 将网络分配到指定的device中
loss_function = nn.CrossEntropyLoss() 
optimizer = optim.Adam(net.parameters(), lr=0.001) 

for epoch in range(5): 

    running_loss = 0.0
    time_start = time.perf_counter()
    for step, data in enumerate(train_loader, start=0):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = net(inputs.to(device))				  # 将inputs分配到指定的device中
        loss = loss_function(outputs, labels.to(device))  # 将labels分配到指定的device中
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if step % 1000 == 999:    
            with torch.no_grad(): 
                outputs = net(test_image.to(device)) # 将test_image分配到指定的device中
                predict_y = torch.max(outputs, dim=1)[1]
                accuracy = (predict_y == test_label.to(device)).sum().item() / test_label.size(0) # 将test_label分配到指定的device中

                print('[%d, %5d] train_loss: %.3f  test_accuracy: %.3f' %
                      (epoch + 1, step + 1, running_loss / 1000, accuracy))

                print('%f s' % (time.perf_counter() - time_start))
                running_loss = 0.0

print('Finished Training')

save_path = './Lenet.pth'
torch.save(net.state_dict(), save_path)

```

打印信息如下：

```python
cuda
[1,  1000] train_loss: 1.569  test_accuracy: 0.527
18.727597 s
[2,  1000] train_loss: 1.235  test_accuracy: 0.595
17.367685 s
[3,  1000] train_loss: 1.076  test_accuracy: 0.623
17.654908 s
[4,  1000] train_loss: 0.984  test_accuracy: 0.639
17.861825 s
[5,  1000] train_loss: 0.917  test_accuracy: 0.649
17.733115 s
Finished Training

```



## 3. predict.py

### 3.1 导入包

```python
#导入包
import torch
import torchvision.transforms as transforms
from PIL import Image  #图像库
from model import LeNet
```



### 3.2 数据预处理

#### 3.2.1 图像数据缩放及归一化、标准化

```python
# 图像数据缩放及归一化、标准化
    transform = transforms.Compose(
        [transforms.Resize((32, 32)),# 首先需resize成跟训练集图像一样的大小（对图像进行缩放成32*32）
         transforms.ToTensor(),#然后转化成Tensor（张量）
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #接着进行标准化处理
```



#### 3.2.2 图像分类标签、名称

```python
# 预测
    classes = ('plane', 'car', 'bird', 'cat',
               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
```



#### 3.2.3 实例化网络，加载训练好的模型参数

```python
    # 实例化网络，加载训练好的模型参数
    net = LeNet()
    net.load_state_dict(torch.load('Lenet.pth'))#加载模型权重参数
```



#### 3.2.4 导入要测试/识别的图像（自己找的，不在数据集中)

```python
# 导入要测试的图像（自己找的，不在数据集中），放在源文件目录下
    x = input("请输入需要识别的文件：")
    im = Image.open(x) #通过Image模块进行图像加载
    im = transform(im)  # [C, H, W]
    im = torch.unsqueeze(im, dim=0)  # 对数据增加一个新维度(batch)，因为tensor的参数是[batch, channel, height, width]
```



#### 3.2.5 对输入的图片（需要预测的图片）不求其损失梯度

```python
 with torch.no_grad():   #不需要求其损失梯度
        outputs = net(im)  #将图像传到网络中进行输出
        predict = torch.max(outputs, dim=1)[1].data.numpy()
    print(classes[int(predict)])
```



#### **3.2.6 predict.py.完整代码**

```python
#导入包
import torch
import torchvision.transforms as transforms
from PIL import Image  #图像库
from model import LeNet

# 数据预处理
def main():
    transform = transforms.Compose(
        [transforms.Resize((32, 32)),# 首先需resize成跟训练集图像一样的大小（对图像进行缩放成32*32）
         transforms.ToTensor(),#然后转化成Tensor（张量）
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #接着进行标准化处理
    # 预测
    classes = ('plane', 'car', 'bird', 'cat',
               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
    # 实例化网络，加载训练好的模型参数
    net = LeNet()
    net.load_state_dict(torch.load('Lenet.pth'))#加载模型权重参数
    # 导入要测试的图像（自己找的，不在数据集中），放在源文件目录下
    x = input("请输入需要识别的文件：")
    im = Image.open(x) #通过Image模块进行图像加载
    im = transform(im)  # [C, H, W]
    im = torch.unsqueeze(im, dim=0)  # 对数据增加一个新维度，因为tensor的参数是[batch, channel, height, width]


    with torch.no_grad():   #不需要求其损失梯度
        outputs = net(im)  #将图像传到网络中进行输出
        predict = torch.max(outputs, dim=1)[1].data.numpy()#输出outputs中的最大值（index索引）
    print(classes[int(predict)])


if __name__ == '__main__':
    main()

```



输出即为预测的标签。

其实预测结果也可以用 **softmax** 表示，输出10个概率：

```python
with torch.no_grad():
    outputs = net(im)
    predict = torch.softmax(outputs, dim=1)
print(predict)

```



输出结果中最大概率值对应的索引即为 预测标签 的索引。

```python
tensor([[2.2782e-06, 2.1008e-07, 1.0098e-04, 9.5135e-05, 9.3220e-04, 2.1398e-04,
         3.2954e-08, 9.9865e-01, 2.8895e-08, 2.8820e-07]])
```

