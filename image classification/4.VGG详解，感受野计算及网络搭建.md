# 4.VGG详解，感受野计算及网络搭建

## VGG详解

VGG 在2014年由牛津大学著名研究组 **VGG**（**Visual Geometry Group**）提出，斩获该年 ImageNet 竞赛中 Localization Task（定位任务）第一名和 Classification Task（分类任务）第二名。

**VGG网络的创新点**：**通过堆叠多个小卷积核来替代大尺度卷积核，可以减少训练参数，同时能保证相同的感受野。**论文中提到，可以通过堆叠两个3×3的卷积核替代5x5的卷积核，堆叠三个3×3的卷积核替代7x7的卷积核。

### 1. CNN感受野

- 概念：在卷积神经网络中，**决定某一层输出结果中一个元素所对应的输入层的区域大小**，被称作感受野（receptive field）。通俗的解释是，输出feature map上的一个单元 对应 输入层上的区域大小。


以下图为例，输出层 layer3 中一个单元 对应 输入层 layer2 上区域大小为2×2（池化操作），对应输入层 layer1 上大小为5×5（可以这么理解，layer2中 2×2区域中的每一块对应一个3×3的卷积核，又因为 stride=2，所以layer1的感受野为5×5）![image-20220907142402198](https://gitee.com/long_chaohuo/images/raw/master/image-20220907142402198.png)

- **感受野的计算公式为：**

  ![image-20220907142425496](https://gitee.com/long_chaohuo/images/raw/master/image-20220907142425496.png)

  ![image-20220907142451547](https://gitee.com/long_chaohuo/images/raw/master/image-20220907142451547.png)!![image-20220907142534641](https://gitee.com/long_chaohuo/images/raw/master/image-20220907142534641.png)

  

  ### 2. 小卷积核

  验证下VGG论文中的两点结论：

  **1.堆叠两个3×3的卷积核替代5x5的卷积核，堆叠三个3×3的卷积核替代7x7的卷积核。替代前后感受野是否相同？**（注：VGG网络中卷积的Stride默认为1）

  ![image-20220907142554591](https://gitee.com/long_chaohuo/images/raw/master/image-20220907142554591.png)

  **2.堆叠3×3卷积核后训练参数是否真的减少了？**

  注：CNN参数个数 = 卷积核尺寸×卷积核深度 × 卷积核组数 = 卷积核尺寸 × 输入特征矩阵深度 × 输出特征矩阵深度
  现假设 输入特征矩阵深度 = 输出特征矩阵深度 = C

  ![image-20220907142606037](https://gitee.com/long_chaohuo/images/raw/master/image-20220907142606037.png)

### 3. VGG-16

VGG网络有多个版本，一般常用的是**VGG-16模型**，其网络结构如下如所示

![image-20220907142617620](https://gitee.com/long_chaohuo/images/raw/master/image-20220907142617620.png)

**经3×3卷积的特征矩阵的尺寸是不改变的：**

![image-20220907142634874](https://gitee.com/long_chaohuo/images/raw/master/image-20220907142634874.png)

## pytorch搭建VGG网络

### 1. model.py

​	跟AlexNet中网络模型的定义一样，VGG网络也是分为 **提取特征网络结构** 和 **分类网络结构**这两个模块

- **提取特征网络结构**：卷积层、池化层

- **分类网络结构：**全连接层

  ![image-20220907142650129](https://gitee.com/long_chaohuo/images/raw/master/image-20220907142650129.png)

  



#### 	1.0 导入包

```python
#导入包
import torch.nn as nn
import torch
```



#### 1.1 VGG网络模型配置列表

```python
# vgg网络模型配置列表，数字表示卷积核个数，'M'表示最大池化层
cfgs = {
    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],											# 模型A
    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],									# 模型B
    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],					# 模型D
    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'], 	# 模型E
}

```



#### 1.2  **提取特征网络结构**

```python
# 卷积层提取特征
def make_features(cfg: list): # 传入的是具体某个模型的参数列表
    layers = [] #创建空列表，用来存放层结构
    in_channels = 3		# 输入的原始图像(rgb三通道)
    for v in cfg:  #遍历模型参数列表
        # 最大池化层
        if v == "M":  #池化层
            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]#定义最大值池化层（大小、步距为2）
        # 卷积层
        else:
            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)#定义卷积层（in_channels（通道数），v（卷积核个数））
            layers += [conv2d, nn.ReLU(True)]  #卷积层都是使用relu激活函数
            in_channels = v #遍历时V自动对应上一层的个数
    return nn.Sequential(*layers)  # 单星号(*)将参数以元组(tuple)的形式导入
```



#### 1.3 分类网络结构

```python
    self.classifier = nn.Sequential(	# 全连接层进行分类，全连接层创建并进行打包  
        nn.Dropout(p=0.5),# Dropout 随机失活神经元，默认比例为0.5
        nn.Linear(512*7*7, 2048),,#第一个全连接（全连接是一纬的向量，节点数为2048个）
        nn.ReLU(True),#relu激活函数
        nn.Dropout(p=0.5),
        nn.Linear(2048, 2048),
        nn.ReLU(True),
        nn.Linear(2048, num_classes)
```



#### 1.4前向传播过程

```python
def forward(self, x#x代表输入的数据（batch[一批图像的个数],channel,height,width）
        # N x 3 x 224 x 224
        x = self.features(x#传入提取特征网络结构（卷积层、池化层）
        # N x 512 x 7 x 7
        x = torch.flatten(x, start_dim=1# 展平,#start_dim=1(因为第一个[0]维度是batch)
        # N x 512*7*7
        x = self.classifier(x)#传入分类网络结构全连接层
        return x
```



#### 1.5网络权重初始化

注意：**实际上 pytorch 在构建网络时会自动初始化权重

```python
def _initialize_weights(self):
        for m in self.modules#遍历self.modules#（遍历神经网络的全部层结构）
            if isinstance(m, nn.Conv2d# 若是卷积层
                # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu# 用（何）kaiming_normal_法初始化权重
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                # nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)
```



#### 1.6实例化VGG特定的模型

```python
#实例化VGG特定的模型
def vgg(model_name="vgg16", **kwargs):  # 双星号(**)将参数以字典的形式导入
    try:
        cfg = cfgs[model_name]
    except:
        print("Warning: model number {} not in cfgs dict!".format(model_name))
        exit(-1)
    model = VGG(make_features(cfg), **kwargs)#返回VGG类中方法
    return model


```





#### 1.7 model.py完整代码

```python
#导入包
import torch.nn as nn
import torch
#定义一个类（AlexNet），继承来自nn.Module这个父类
class VGG(nn.Module):
    def __init__(self, features, num_classes=1000, init_weights=False# 定义初始化函数（num_classes(分类类别个数)，init_weights（初始化权重），features（提取特征网络结构））
        super(VGG, self).__init__()
        self.features = features			# 卷积层提取特征
        self.classifier = nn.Sequential(	# 全连接层进行分类
            nn.Dropout(p=0.5),
            nn.Linear(512*7*7, 2048),
            nn.ReLU(True),
            nn.Dropout(p=0.5),
            nn.Linear(2048, 2048),
            nn.ReLU(True),
            nn.Linear(2048, num_classes)
        )
        if init_weights:
            self._initialize_weights()

    def forward(self, x#x代表输入的数据（batch[一批图像的个数],channel,height,width）
        # N x 3 x 224 x 224
        x = self.features(x#传入提取特征网络结构（卷积层、池化层）
        # N x 512 x 7 x 7
        x = torch.flatten(x, start_dim=1# 展平,#start_dim=1(因为第一个[0]维度是batch)
        # N x 512*7*7
        x = self.classifier(x)#传入分类网络结构全连接层
        return x

    def _initialize_weights(self):
        for m in self.modules#遍历self.modules#（遍历神经网络的全部层结构）
            if isinstance(m, nn.Conv2d# 若是卷积层
                # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu# 用（何）kaiming_normal_法初始化权重
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                # nn.init.normal_(m.weight, 0, 0.01)
                nn.init.constant_(m.bias, 0)

# 卷积层提取特征
def make_features(cfg: list): # 传入的是具体某个模型的参数列表
    layers = [] #创建空列表，用来存放层结构
    in_channels = 3		# 输入的原始图像(rgb三通道)
    for v in cfg:  #遍历模型参数列表
        # 最大池化层
        if v == "M":  #池化层
            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]#定义最大值池化层（大小、步距为2）
        # 卷积层
        else:
            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)#定义卷积层（in_channels（通道数），v（卷积核个数））
            layers += [conv2d, nn.ReLU(True)]  #卷积层都是使用relu激活函数
            in_channels = v #遍历时V自动对应上一层的个数
    return nn.Sequential(*layers)  # 单星号(*)将参数以元组(tuple)的形式导入

# vgg网络模型配置列表，数字表示卷积核个数，'M'表示最大池化层
cfgs = {
    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],											# 模型A
    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],									# 模型B
    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],					# 模型D
    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'], 	# 模型E
}
def vgg(model_name="vgg16", **kwargs):  # 双星号(**)将参数以字典的形式导入
    try:
        cfg = cfgs[model_name]
    except:
        print("Warning: model number {} not in cfgs dict!".format(model_name))
        exit(-1)
    model = VGG(make_features(cfg), **kwargs)#返回VGG类中方法
    return model


```



### 2. train.py

#### 2.0导入包及使用GPU训练

- 使用GPU训练`torch.device("cuda" if torch.cuda.is_available() else "cpu")`

```python
#导入包
import os
import sys
import json
import torch
import torch.nn as nn
from torchvision import transforms, datasets
import torch.optim as optim
from tqdm import tqdm

from model import vgg

# 使用GPU训练
def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))
```



#### 2.1 数据预处理

需要注意的是，对训练集的预处理，多了**随机裁剪**和**水平翻转**这两个步骤。可以起到扩充数据集的作用，增强模型泛化能力。

- 随机裁剪`transforms.RandomResizedCrop(224)`，随机裁剪，再缩放成 224×224

- 水平翻转`transforms.RandomHorizontalFlip()`, 水平方向随机翻转

  ```python
  #**随机裁剪**和**水平翻转**
  data_transform = {
      "train": transforms.Compose([transforms.RandomResizedCrop(224),       # 随机裁剪，再缩放成 224×224
                                   transforms.RandomHorizontalFlip(),  # 水平方向随机翻转，概率为 0.5, 即一半的概率翻转, 一半的概率不翻转
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),
  
      "val": transforms.Compose([transforms.Resize((224, 224)),  # cannot 224, must (224, 224)
                                 transforms.ToTensor(),
                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}
  
  
  ```

  

#### 2.2 导入、加载 训练集

```python
# 获取图像数据集的路径
data_root = os.path.abspath(os.path.join(os.getcwd(), "../.."))  		# get data root path 返回上上层目录
image_path = data_root + "/data_set/flower_data/"  				 		# flower data_set path
# 导入训练集并进行预处理
train_dataset = datasets.ImageFolder(root=os.path.join(image_path, "train"),
                                         transform=data_transform["train"])
    train_num = len(train_dataset)
# 按batch_size分批次加载训练集
batch_size = 32# 每批训练的样本数
    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers，查看cpu的数量，对工作时的线程数进行输入
    print('Using {} dataloader workers every process'.format(nw))

    train_loader = torch.utils.data.DataLoader(train_dataset,# 导入的训练集
                                               batch_size=batch_size, # 每批训练的样本数
                                               shuffle=True,# 是否打乱训练集
                                               num_workers=nw)# 使用线程数

```



#### 2.3 导入、加载 验证集

```python
# 导入验证集并进行预处理
validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, "val"),
                                            transform=data_transform["val"])
val_num = len(validate_dataset)
# 导入验证集并进行预处理
 validate_loader = torch.utils.data.DataLoader(validate_dataset,
                                                  batch_size=batch_size,  shuffle=False, num_workers=nw)
    print("using {} images for training, {} images for validation.".format(train_num,val_num))
```



#### 2.4存储 索引：标签 的字典

为了方便在 predict 时读取信息，将 索引：标签 存入到一个 `json` 文件中

```python
# 字典，类别：索引 {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}
flower_list = train_dataset.class_to_idx
# 将 flower_list 中的 key 和 val 调换位置
cla_dict = dict((val, key) for key, val in flower_list.items())

# 将 cla_dict 写入 json 文件中
json_str = json.dumps(cla_dict, indent=4)
with open('class_indices.json', 'w') as json_file:
    json_file.write(json_str)

```

class_indices.json` 文件内容如下:

```python
{
    "0": "daisy",
    "1": "dandelion",
    "2": "roses",
    "3": "sunflowers",
    "4": "tulips"
}

```



#### 2.5 训练过程

训练过程中需要注意：

- `net.train()`：训练过程中开启 Dropout

- `net.eval()`： 验证过程关闭 Dropout

##### 2.5.1实例化AlexNe网络模型（损失函数、优化器）

- `nn.CrossEntropyLoss()` 函数：结合了nn.LogSoftmax()和nn.NLLLoss()两个函数

- `optim.Adam(net.parameters(), 0.0002)`  函数：net.parameters代表训练参数即LetNet网络模型的可训练全部参数，lr代表学习率

```python
# 实例化网络（输出类型为5，初始化权重）
model_name = "vgg16"
    net = vgg(model_name=model_name, num_classes=5, init_weights=True)
    net.to(device) # 分配网络到指定的设备（GPU/CPU）训练
    loss_function = nn.CrossEntropyLoss()  # 交叉熵损失
    optimizer = optim.Adam(net.parameters(), lr=0.0001)# 优化器（训练参数，学习率）
```

-----------------------------------------------------------------------------------------------------------------------------------

```python
#函数调用关系：
net = vgg(model_name="vgg16", num_classes=5, init_weights=True)
cfg = cfgs[model_name]
  = cfgs[vgg16] = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']
model = VGG(make_features(cfg), num_classes=5, init_weights=True)
make_features(cfg: list)
注：VGG网络模型较深，需要使用GPU进行训练(而且要内存大一点的GPU，我笔记本那2GB的GPU跑不动，pytorch会报错GPU内存不足)
```



##### 2.5.2 进入模型训练过程

- 设置训练集进行多少次训练

- 遍历训练集，获取训练集的图像和标签

- 清除历史梯度

- 正向传播

- 计算损失

- 反向传播

- 优化器更新参数

```python
#进入模型训练过程
    epochs = 30
    for epoch in range(epochs):
        # train
        net.train# 训练过程中开启 Dropout
        running_loss = 0.# 每个 epoch 都会对 running_loss  清零
        train_bar = tqdm(train_loader, file=sys.stdout)
        for step, data in enumerate(train_bar): # 遍历训练集，step从0开始计算
            images, labels = data# 获取训练集的图像和标签
            optimizer.zero_grad()# 清除历史梯度
            outputs = net(images.to(device))# 正向传播
            loss = loss_function(outputs, labels.to(device))# 计算损失
            loss.backward() # 反向传播
            optimizer.step() # 优化器更新参数

            # print statistics
            running_loss += loss.item()

            train_bar.desc = "train epoch[{}/{}] loss:{:.3f}".format(epoch + 1,
                                                                     epochs,
                                                                     loss)
```

#####      2.5.3 打印训练进度（使训练过程可视化）                       

```python
 # print statistics
            running_loss += loss.item()

            train_bar.desc = "train epoch[{}/{}] loss:{:.3f}".format(epoch + 1,
                                                                     epochs,
                                                                     loss)
```

#####                              

#####  2.5.4验证训练精度、损失、准确率等数据（结果）

```python
# validate
        net.eval # 验证过程中关闭 Dropout
        acc = 0.0  # accumulate accurate number / epoch
        with torch.no_grad():
            val_bar = tqdm(validate_loader, file=sys.stdout)
            for val_data in val_bar:
                val_images, val_labels = val_data
                outputs = net(val_images.to(device))
                predict_y = torch.max(outputs, dim=1)[1# 以output中值最大位置对应的索引（标签）作为预测输出
                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()

        val_accurate = acc / val_num
        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %
              (epoch + 1, running_loss / train_steps, val_accurate))
```





##### 2.5.5 保存训练参数

-  `torch.save(net.state_dict(), save_path)`

​		net.state_dict()：以字典的形式

​		save_path：保存参数的路径

```python
# 保存准确率最高的那次网络参数
        if val_accurate > best_acc:
            best_acc = val_accurate
            torch.save(net.state_dict(), save_path)
            
        print('[epoch %d] train_loss: %.3f  test_accuracy: %.3f \n' %
              (epoch + 1, running_loss / step, val_accurate))

print('Finished Training')
```



#### 2.6trian.py 完整代码

```python
import os
import sys
import json

import torch
import torch.nn as nn
from torchvision import transforms, datasets
import torch.optim as optim
from tqdm import tqdm

from model import vgg


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))

    data_transform = {
        "train": transforms.Compose([transforms.RandomResizedCrop(224),
                                     transforms.RandomHorizontalFlip(),
                                     transforms.ToTensor(),
                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),
        "val": transforms.Compose([transforms.Resize((224, 224)),
                                   transforms.ToTensor(),
                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])}

    data_root = os.path.abspath(os.path.join(os.getcwd(), "../.."))  # get data root path
    image_path = os.path.join(data_root, "data_set", "flower_data")  # flower data set path
    assert os.path.exists(image_path), "{} path does not exist.".format(image_path)
    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, "train"),
                                         transform=data_transform["train"])
    train_num = len(train_dataset)

    # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}
    flower_list = train_dataset.class_to_idx
    cla_dict = dict((val, key) for key, val in flower_list.items())
    # write dict into json file
    json_str = json.dumps(cla_dict, indent=4)
    with open('class_indices.json', 'w') as json_file:
        json_file.write(json_str)

    batch_size = 32
    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers
    print('Using {} dataloader workers every process'.format(nw))

    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=batch_size, shuffle=True,
                                               num_workers=nw)

    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, "val"),
                                            transform=data_transform["val"])
    val_num = len(validate_dataset)
    validate_loader = torch.utils.data.DataLoader(validate_dataset,
                                                  batch_size=batch_size, shuffle=False,
                                                  num_workers=nw)
    print("using {} images for training, {} images for validation.".format(train_num,
                                                                           val_num))

    # test_data_iter = iter(validate_loader)
    # test_image, test_label = test_data_iter.next()

    model_name = "vgg16"
    net = vgg(model_name=model_name, num_classes=5, init_weights=True)
    net.to(device)
    loss_function = nn.CrossEntropyLoss()
    optimizer = optim.Adam(net.parameters(), lr=0.0001)

    epochs = 30
    best_acc = 0.0
    save_path = './{}Net.pth'.format(model_name)
    train_steps = len(train_loader)
    for epoch in range(epochs):
        # train
        net.train()
        running_loss = 0.0
        train_bar = tqdm(train_loader, file=sys.stdout)
        for step, data in enumerate(train_bar):
            images, labels = data
            optimizer.zero_grad()
            outputs = net(images.to(device))
            loss = loss_function(outputs, labels.to(device))
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()

            train_bar.desc = "train epoch[{}/{}] loss:{:.3f}".format(epoch + 1,
                                                                     epochs,
                                                                     loss)

        # validate
        net.eval()
        acc = 0.0  # accumulate accurate number / epoch
        with torch.no_grad():
            val_bar = tqdm(validate_loader, file=sys.stdout)
            for val_data in val_bar:
                val_images, val_labels = val_data
                outputs = net(val_images.to(device))
                predict_y = torch.max(outputs, dim=1)[1]
                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()

        val_accurate = acc / val_num
        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f' %
              (epoch + 1, running_loss / train_steps, val_accurate))

        if val_accurate > best_acc:
            best_acc = val_accurate
            torch.save(net.state_dict(), save_path)

    print('Finished Training')


if __name__ == '__main__':
    main()

```



### 3. predict.py

#### 3.1 导入包

```python
#导入包
import torch
from model import AlexNet
from PIL import Image
from torchvision import transforms
import matplotlib.pyplot as plt
import json
```



#### 3.2 数据预处理

##### 3.2.1 图像数据缩放及归一化、标准化

```python
# 图像数据缩放及归一化、标准化
    transform = transforms.Compose(
        [transforms.Resize((224, 224)),# 首先需resize成跟训练集图像一样的大小（对图像进行缩放成224*224）
         transforms.ToTensor(),#然后转化成Tensor（张量）
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #接着进行标准化处理
    
```



##### 3.2.2 导入要测试/识别的图像（自己找的，不在数据集中)

```python
# 导入要测试的图像（自己找的，不在数据集中），放在源文件目录下
img = Image.open("蒲公英.jpg")
plt.imshow(img)
# [N, C, H, W]
img = data_transform(img)#数据预处理
# expand batch dimension
img = torch.unsqueeze(img, dim=0)# 对数据增加一个新维度，因为tensor的参数是[batch, channel, height, width]
```



##### 3.2.3 读取在train.py中存储的图像对于标签的json文件

```python
# read class_indict
try:
    json_file = open('./class_indices.json', 'r')#对json文件进行读取
    class_indict = json.load(json_file)#duijson文件进行解密，变成我们可以用的字典
except Exception as e:
    print(e)
    exit(-1)
```



##### 3.2.4 实例化网络，加载训练好的模型参数

```python
# create model，实例化网络，加载训练好的模型参数
model = AlexNet(num_classes=5)
# load model weights
model_weight_path = "./AlexNet.pth"
model.load_state_dict(torch.load(model_weight_path))#把权重载入网络模型

```



##### 3.2.5 对输入的图片（需要预测的图片）不求其损失梯度

```python
# 关闭 Dropout
model.eval()
with torch.no_grad():
    # predict class
    output = torch.squeeze(model(img))     # 将输出压缩，即压缩掉 batch 这个维度
    predict = torch.softmax(output, dim=0)
    predict_cla = torch.argmax(predict).numpy()
print(class_indict[str(predict_cla)], predict[predict_cla].item())
plt.show()

```



#### **3.3predict.py.完整代码**    

```python
#导入包
import torch
from model import AlexNet
from PIL import Image
from torchvision import transforms
import matplotlib.pyplot as plt
import json

# 预处理
data_transform = transforms.Compose(
    [transforms.Resize((224, 224)),# 首先需resize成跟训练集图像一样的大小
     transforms.ToTensor(),#转化为张量（Tensor）,是将输入的数据shape W，H，C ——> C，W，H,将所有数除以255，将数据归一化到【0，1】
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#标准化处理x = (x - mean) / std

# 导入要测试的图像（自己找的，不在数据集中），放在源文件目录下
img = Image.open("蒲公英.jpg")
plt.imshow(img)
# [N, C, H, W]
img = data_transform(img)#数据预处理
# expand batch dimension
img = torch.unsqueeze(img, dim=0)# 对数据增加一个新维度，因为tensor的参数是[batch, channel, height, width]

# read class_indict
try:
    json_file = open('./class_indices.json', 'r')#对json文件进行读取
    class_indict = json.load(json_file)#duijson文件进行解密，变成我们可以用的字典
except Exception as e:
    print(e)
    exit(-1)

# create model，实例化网络，加载训练好的模型参数
model = AlexNet(num_classes=5)
# load model weights
model_weight_path = "./AlexNet.pth"
model.load_state_dict(torch.load(model_weight_path))#把权重载入网络模型

# 关闭 Dropout
model.eval()
with torch.no_grad():
    # predict class
    output = torch.squeeze(model(img))     # 将输出压缩，即压缩掉 batch 这个维度
    predict = torch.softmax(output, dim=0)
    predict_cla = torch.argmax(predict).numpy()
print(class_indict[str(predict_cla)], predict[predict_cla].item())
plt.show()

```

打印出预测的标签以及概率值：

```python
dandelion 0.7221569418907166
```

